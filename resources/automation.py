import os
import pandas as pd
import docx
import pypdf

from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from docling.document_converter import DocumentConverter

# Carregar vari√°veis do .env
load_dotenv()
openai_api_key = os.getenv("OPENAI_API_KEY")

# Criar modelo LLM para resumo
llm = ChatOpenAI(model_name="gpt-4", openai_api_key=openai_api_key)

# Criar conversor de documentos com DocLing
converter = DocumentConverter()

# Fun√ß√£o para extrair dados de documentos
def extract_data(file_path):
    """Processa um documento e retorna seu conte√∫do extra√≠do."""
    if file_path.endswith((".pdf", ".docx", ".xlsx", ".csv", ".txt")):
        try:
            print(f"üìÇ Processando: {file_path}")

            result = converter.convert(file_path)
            if result.status.value.lower() != "success":
                print(f"‚ö† Erro ao processar {file_path}: {result.status}")
                return None

            doc = result.document  # Pegamos o documento processado pelo Docling

            extracted_text = []

            # Percorre os textos do corpo do documento
            for text_item in doc.texts:
                if hasattr(text_item, 'text') and text_item.text:  # Verifica se tem conte√∫do
                    extracted_text.append(text_item.text.strip())

            print(f"üîç Resultado da convers√£o: {extracted_text}")  # Debug

            # Junta todo o texto extra√≠do com quebras de linha
            return "\n".join(extracted_text)

        except Exception as e:
            print(f"‚ö† Erro ao processar {file_path}: {e}")
            return ""
    return ""

# Fun√ß√£o para gerar um relat√≥rio estruturado
def generate_report(data):
    """Gera um relat√≥rio formatado a partir dos dados extra√≠dos."""
    doc = docx.Document()
    doc.add_heading("Relat√≥rio Automatizado", level=1)
    doc.add_paragraph(data)
    
    report_path = "output/relatorio_automatizado.docx"
    doc.save(report_path)
    print(f"üìÑ Relat√≥rio salvo em: {report_path}")

# Fun√ß√£o para resumir conte√∫do usando IA
def summarize_text(text):

    MAX_TOKENS = 4000  # Definir um limite para cada requisi√ß√£o ao GPT
    chunks = [text[i:i+MAX_TOKENS] for i in range(0, len(text), MAX_TOKENS)]

    """Resume um texto longo utilizando IA."""
    try:
        print("‚è≥ Gerando resumo...")
        summaries = []
        for chunk in chunks:
            response = llm.invoke(chunk)  # Usando `invoke()` em vez de `__call__`
            summaries.append(response.content)

        return " ".join(summaries)
    except Exception as e:
        print(f"‚ö† Erro ao resumir texto: {e}")
        return "Erro ao gerar resumo."

# Criar pasta de sa√≠da se n√£o existir
if not os.path.exists("output"):
    os.makedirs("output")

# Testar o fluxo
if __name__ == "__main__":
    # Documento para teste
    test_file = "data/exemplo.docx"

    # Extra√ß√£o
    text_data = extract_data(test_file)
    if text_data:
        print("‚úÖ Dados extra√≠dos com sucesso!")

        # Resumo do conte√∫do
        summary = summarize_text(text_data)
        print("üìå Resumo Gerado:\n", summary)

        # Gera√ß√£o de relat√≥rio
        generate_report(summary)
